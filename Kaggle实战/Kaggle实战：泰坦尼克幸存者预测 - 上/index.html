<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-loading-bar.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.7.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":true,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="泰坦尼克幸存者预测是Kaggle上数据竞赛的入门级别的比赛，我曾经在一年前作为作业参加过这个比赛，我想要再次从这个比赛开始，尝试不同的模型，来当作在Kaggle比赛的起点。">
<meta property="og:type" content="article">
<meta property="og:title" content="Kaggle实战：泰坦尼克幸存者预测 - 上">
<meta property="og:url" content="http://yoursite.com/Kaggle%E5%AE%9E%E6%88%98/Kaggle%E5%AE%9E%E6%88%98%EF%BC%9A%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%B9%B8%E5%AD%98%E8%80%85%E9%A2%84%E6%B5%8B%20-%20%E4%B8%8A/index.html">
<meta property="og:site_name" content="Daniel的博客">
<meta property="og:description" content="泰坦尼克幸存者预测是Kaggle上数据竞赛的入门级别的比赛，我曾经在一年前作为作业参加过这个比赛，我想要再次从这个比赛开始，尝试不同的模型，来当作在Kaggle比赛的起点。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219004204507.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219004331914.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219004346178.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219114020233.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219114533289.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219115144234.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219115642827.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200219123329275.png">
<meta property="article:published_time" content="2020-02-19T04:41:28.000Z">
<meta property="article:modified_time" content="2020-02-21T12:34:26.447Z">
<meta property="article:author" content="DanielRX">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200219004204507.png">

<link rel="canonical" href="http://yoursite.com/Kaggle%E5%AE%9E%E6%88%98/Kaggle%E5%AE%9E%E6%88%98%EF%BC%9A%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%B9%B8%E5%AD%98%E8%80%85%E9%A2%84%E6%B5%8B%20-%20%E4%B8%8A/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Kaggle实战：泰坦尼克幸存者预测 - 上 | Daniel的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Daniel的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/Dai98" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Kaggle%E5%AE%9E%E6%88%98/Kaggle%E5%AE%9E%E6%88%98%EF%BC%9A%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%B9%B8%E5%AD%98%E8%80%85%E9%A2%84%E6%B5%8B%20-%20%E4%B8%8A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="DanielRX">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Daniel的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kaggle实战：泰坦尼克幸存者预测 - 上
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-19 12:41:28" itemprop="dateCreated datePublished" datetime="2020-02-19T12:41:28+08:00">2020-02-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-21 20:34:26" itemprop="dateModified" datetime="2020-02-21T20:34:26+08:00">2020-02-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kaggle%E5%AE%9E%E6%88%98/" itemprop="url" rel="index">
                    <span itemprop="name">Kaggle实战</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>泰坦尼克幸存者预测是Kaggle上数据竞赛的入门级别的比赛，我曾经在一年前作为作业参加过这个比赛，我想要再次从这个比赛开始，尝试不同的模型，来当作在Kaggle比赛的起点。</p>
<a id="more"></a>
<p>关于此次竞赛，我想分成两个部分，第一个部分基于PyTorch建立神经网络，第二个部分使用sklearn做多个分类器投票。</p>
<p>使用的编程环境及依赖包版本：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> IPython</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">os.environ[<span class="string">'CUDA_LAUNCH_BLOCKING'</span>] = <span class="string">"1"</span></span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/20200219004204507.png" alt="在这里插入图片描述"></p>
<h3 id="一、数据预处理"><a href="#一、数据预处理" class="headerlink" title="一、数据预处理"></a>一、数据预处理</h3><p>首先我们看看数据中有多少空缺值：</p>
<p>​                            <img src="https://img-blog.csdnimg.cn/20200219004331914.png" alt=""><img src="https://img-blog.csdnimg.cn/20200219004346178.png" alt=""></p>
<p>我们可以看到，<strong>Age</strong>、<strong>Cabin</strong>、<strong>Embarked</strong>和<strong>Fare</strong>有空缺值。<strong>Cabin</strong>有78%的空缺值，而且其余值也没有明显的规律，我们在之后可以直接删除改列。对于其他值，我们可以对Age和<strong>Fare</strong>补充中位数，把<strong>Embarked</strong>补充频率最高的值。</p>
<p>我们可以把训练数据train与测试数据test拼接在一起，一起来进行处理，可以省去各自处理的麻烦。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = [train,test]</span><br><span class="line"></span><br><span class="line">train_backup = train.copy()</span><br><span class="line">test_backup = test.copy()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> data:</span><br><span class="line">    dataset[<span class="string">"Age"</span>].fillna(dataset[<span class="string">"Age"</span>].median(),inplace = <span class="literal">True</span>)</span><br><span class="line">    dataset[<span class="string">"Fare"</span>].fillna(dataset[<span class="string">"Fare"</span>].median(),inplace = <span class="literal">True</span>)</span><br><span class="line">    dataset[<span class="string">"Embarked"</span>].fillna(dataset[<span class="string">"Embarked"</span>].mode()[<span class="number">0</span>],inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>这里有一点需要提醒，如果我们使用for循环来对两个数据集依次进行处理，需要注意Python在对列表值的遍历的时候提供的值是列表值中的浅拷贝，也就是说<code>dataset</code>和<code>data[0]</code>中的值对应的是一个指针，然而是两个不同的对象。所以对<code>dataset</code>做重赋值的情况，并不会真正改变<code>train</code>和<code>test</code>两个数据集。Pandas中有些函数(<code>drop</code>,<code>apply</code>等)可以对数据集进行操作来改变数据集，但记得要把<code>inplace</code>参数设置为True。如果想要在循环中修改数据集的值，一定要记得通过索引来访问列表！</p>
<p>现在没有了空缺值，我们来处理一下其他的数据。我们从<strong>Name</strong>开始，虽然一个人叫什么不会影响他/她是否幸存，但如果你自己观察，每个人的名字中间带有他们的称谓，或者前缀（Mr, Mrs），能从一定程度上反映出他/她的性别和社会地位，也会一定程度的影响幸存与否。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">threshhold = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> data:</span><br><span class="line">    </span><br><span class="line">    dataset[<span class="string">"Prefix"</span>] = dataset[<span class="string">"Name"</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">" "</span>)[<span class="number">1</span>])</span><br><span class="line">    freq = (dataset[<span class="string">"Prefix"</span>].value_counts() &lt; threshhold)</span><br><span class="line">    dataset[<span class="string">"Prefix"</span>] = dataset[<span class="string">"Prefix"</span>].apply(<span class="keyword">lambda</span> x: <span class="string">"others"</span> <span class="keyword">if</span> freq.loc[x] <span class="keyword">else</span> x)</span><br></pre></td></tr></table></figure><br>这里我发现称谓的种类实在太多了，有许多只出现了一两次，所以我把所有出现低于10次的称谓都重新赋为”others”。</p>
<p>我们来继续处理其他变量。我看到<strong>SibSp</strong>和<strong>Parch</strong>代表船上兄弟姐妹、配偶、父母、孩子的数量，可以把它们相加来代表家人的数量，并再添加一个二元变量，代表该人当时在船上是否只有一个人。注意，我再相加的时候多加了1，代表整个家庭的人数，你也可以不加1，代表他/她的家人的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> data:</span><br><span class="line">    <span class="comment"># The size of the whole family</span></span><br><span class="line">    dataset[<span class="string">"Family"</span>] = dataset[<span class="string">"Parch"</span>] + dataset[<span class="string">"SibSp"</span>] + <span class="number">1</span> </span><br><span class="line">    dataset[<span class="string">"IsAlone"</span>] = dataset[<span class="string">"Family"</span>].apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x == <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    dataset[<span class="string">"FareBin"</span>] = pd.qcut(dataset[<span class="string">"Fare"</span>],<span class="number">4</span>)</span><br><span class="line">    dataset[<span class="string">"AgeBin"</span>] = pd.cut(dataset[<span class="string">"Age"</span>],<span class="number">4</span>)</span><br><span class="line">    dataset[<span class="string">"FamilyBin"</span>] = pd.cut(dataset[<span class="string">"Family"</span>],<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>我又根据数值的大小，将<strong>Fare</strong>、<strong>Age</strong>和<strong>Family</strong>进行分段重新归类。这样的离散化处理使得我们将连续性变量转换为类别型的变量。注意<code>cut</code>函数和<code>qcut</code>的区别，<code>cut</code>函数是将数据分割成等长区间，每个区间的观测值数量不等；<code>qcut</code>是将数据分割成自适应区间，虽然区间的长度是不固定的，但是每个区间的观测值数量是相等的。</p>
<p>然而，如果此时你查看我们的数据，你会发现数据的值变成了区间。为了再之后做独热码的时候变量名更加清晰，我们将变量的值重新赋为数字类别：<br>​                          <img src="https://img-blog.csdnimg.cn/20200219114020233.png" alt=""><img src="https://img-blog.csdnimg.cn/20200219114533289.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">label = preprocessing.LabelEncoder()</span><br><span class="line">label_columns = [<span class="string">"FareBin"</span>,<span class="string">"AgeBin"</span>,<span class="string">"FamilyBin"</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> data:</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> label_column <span class="keyword">in</span> label_columns:</span><br><span class="line">        dataset[label_column] = label.fit_transform(dataset[label_column])</span><br></pre></td></tr></table></figure>
<p>最后一步，因为数字类别的特征会导致类别本身数值大小也成为特征，因此我们把数字类别转换为独热码。例如，类别3转换为[0 0 1]，这样数字本身的大小便不会影响模型了。除此之外，我们再将没有用处的列删除掉。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">drop_columns = [<span class="string">"PassengerId"</span>,<span class="string">"Name"</span>,<span class="string">"Age"</span>,<span class="string">"SibSp"</span>,<span class="string">"Parch"</span>,</span><br><span class="line">				<span class="string">"Ticket"</span>,<span class="string">"Fare"</span>,<span class="string">"Cabin"</span>,<span class="string">"Family"</span>]</span><br><span class="line">dummy_columns = [<span class="string">"Pclass"</span>,<span class="string">"Sex"</span>,<span class="string">"Embarked"</span>,<span class="string">"Prefix"</span>,<span class="string">"FareBin"</span>,<span class="string">"AgeBin"</span>,<span class="string">"FamilyBin"</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i,dataset <span class="keyword">in</span> enumerate(data):</span><br><span class="line">    </span><br><span class="line">    data[i].drop(drop_columns,axis = <span class="number">1</span>,inplace = <span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> dummy <span class="keyword">in</span> dummy_columns:</span><br><span class="line">        dummy_df = pd.get_dummies(dataset[dummy],prefix = dummy)</span><br><span class="line">        data[i] = pd.concat([data[i],dummy_df],axis = <span class="number">1</span>)</span><br><span class="line">        data[i].drop(dummy,axis = <span class="number">1</span>,inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>最后数据的特征：<br><img src="https://img-blog.csdnimg.cn/20200219115144234.png" alt=""></p>
<p>我们再将数据重新分割成训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train = data[<span class="number">0</span>]</span><br><span class="line">test = data[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">train_data = train.drop(<span class="string">"Survived"</span>,axis = <span class="number">1</span>,inplace = <span class="literal">False</span>)</span><br><span class="line">train_target = train[<span class="string">"Survived"</span>]</span><br></pre></td></tr></table></figure>
<h3 id="二、变量选择"><a href="#二、变量选择" class="headerlink" title="二、变量选择"></a>二、变量选择</h3><p>我们通过计算每个变量之间的相关系数，来判断每个变量和目标变量(<strong>Survived</strong>)之间的相关系数，并通过每个变量之间的相关系数来判断多重共线性是否存在。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">correlation = train.corr()</span><br><span class="line"></span><br><span class="line">_, ax = plt.subplots(figsize = (<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">colormap = sns.diverging_palette(<span class="number">220</span>,<span class="number">10</span>,as_cmap = <span class="literal">True</span>)</span><br><span class="line">_ = sns.heatmap(correlation, </span><br><span class="line">            cmap = colormap,</span><br><span class="line">            square = <span class="literal">True</span>,</span><br><span class="line">            cbar_kws = &#123;<span class="string">"shrink"</span>:<span class="number">.6</span>&#125;,</span><br><span class="line">            ax = ax,</span><br><span class="line">            linewidths = <span class="number">0.1</span>, vmax = <span class="number">1.0</span>, linecolor = <span class="string">"white"</span>,</span><br><span class="line">            annot_kws = &#123;<span class="string">"fontsize"</span>:<span class="number">12</span>&#125;</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">"Correlation Heatmap \n"</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://img-blog.csdnimg.cn/20200219115642827.png" alt=""></p>
<p>我们发现相关系数比较高的变量是<strong>Sex</strong>和<strong>Prefix</strong>，也就是如果一个人的性别是男的，他就不可能是女的，并且很大概率被称作”Mr.”。对我们的回归没有很大的影响，我们无需删除。</p>
<h3 id="三、模型搭建"><a href="#三、模型搭建" class="headerlink" title="三、模型搭建"></a>三、模型搭建</h3><p>神经网络的搭建基于PyTorch，首先我们把数据从<code>Pandas</code>的<code>DataFrame</code>转换为<code>Numpy</code>的<code>array</code>，再通过<code>torch</code>的<code>from_numpy</code>函数来生成<code>Tensor</code>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_data = np.array(train_data)</span><br><span class="line">train_target = np.array(train_target)</span><br><span class="line">test = np.array(test)</span><br><span class="line"></span><br><span class="line">data_tensor = torch.from_numpy(train_data).type(torch.FloatTensor)</span><br><span class="line">target_tensor = torch.from_numpy(train_target).type(torch.LongTensor)</span><br><span class="line">test_tensor = torch.from_numpy(test).type(torch.FloatTensor)</span><br></pre></td></tr></table></figure><br>注意，虽然我们的数据集只有0和1两种值，但是必须要设置为<code>FloatTensor</code>，因为稍后要计算交叉熵损失函数；而目标张量<code>target_tensor</code>设置成<code>LongTensor</code>即可。</p>
<p>现在我们来设置一下之后会用到的模型的超参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;</span><br><span class="line">    <span class="string">"USE_CUDA"</span>:torch.cuda.is_available(),</span><br><span class="line">    <span class="string">"N"</span>:train_data.shape[<span class="number">0</span>],</span><br><span class="line">    <span class="string">"D_in"</span>:train_data.shape[<span class="number">1</span>],</span><br><span class="line">    <span class="string">"H"</span>:train_data.shape[<span class="number">1</span>]+<span class="number">1</span>,</span><br><span class="line">    <span class="string">"D_out"</span>:<span class="number">2</span>,</span><br><span class="line">    <span class="string">"learning_rate"</span>:<span class="number">0.02</span>,</span><br><span class="line">    <span class="string">"epoch"</span>:<span class="number">10000</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>下面我们就可以开始创建模型了，在这里我用了三层的神经网络，前两层使用了ReLU激活函数，最后一层使用Sigmoid激活函数来进行二分类，并在中间添加了一层Dropout，来防止过拟合。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,D_in,H,D_out)</span>:</span></span><br><span class="line">        super(Model,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(D_in,H)</span><br><span class="line">        self.linear2 = nn.Linear(H,H)</span><br><span class="line">        self.linear3 = nn.Linear(H,D_out)</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        layer1 = F.relu(self.linear1(x))</span><br><span class="line">        layer2 = F.relu(layer1)</span><br><span class="line">        layer2 = self.dropout(layer2)</span><br><span class="line">        layer3 = F.sigmoid(self.linear3(layer2))</span><br><span class="line">        <span class="keyword">return</span> layer3</span><br><span class="line">             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        pred = self.forward(x)</span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> pred:</span><br><span class="line">            <span class="keyword">if</span> t[<span class="number">0</span>]&gt;t[<span class="number">1</span>]:</span><br><span class="line">                ans.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ans.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.tensor(ans)</span><br></pre></td></tr></table></figure><br>下面我们就可以创建模型对象，以及损失函数、优化器和Scheduler：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = Model(config[<span class="string">"D_in"</span>],config[<span class="string">"H"</span>],config[<span class="string">"D_out"</span>])</span><br><span class="line">loss_func = nn.CrossEntropyLoss()  </span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=config[<span class="string">"learning_rate"</span>])</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><br>Scheduler是帮助我们的Learning rate衰退用的，在下面会详细解释到。</p>
<p>如果安装了CUDA和Cudnn，可以使用GPU加速计算：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> config[<span class="string">"USE_CUDA"</span>]:</span><br><span class="line">    model = model.cuda()</span><br><span class="line">    data_tensor = data_tensor.cuda()</span><br><span class="line">    target_tensor = target_tensor.cuda()</span><br><span class="line">    test_tensor = test_tensor.cuda()</span><br></pre></td></tr></table></figure><br>现在我们开始训练过程：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">losses = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(config[<span class="string">"epoch"</span>]+<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    pred_tensor = model(data_tensor)</span><br><span class="line">    loss = loss_func(pred_tensor,target_tensor)</span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Epoch"</span>,epoch,<span class="string">" loss"</span>,loss.item())</span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        loss_value = loss.item()</span><br><span class="line">        <span class="keyword">if</span> len(losses) == <span class="number">0</span> <span class="keyword">or</span> loss_value &lt; min(losses):</span><br><span class="line">            print(<span class="string">"Minimum Loss Updated"</span>)</span><br><span class="line">            torch.save(model.state_dict(),<span class="string">"model.pth"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"Learning rate decay"</span>)</span><br><span class="line">            scheduler.step()</span><br><span class="line">        losses.append(loss_value)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br></pre></td></tr></table></figure><br>在这里，我设置了每500轮显示一次损失函数的值；每1000轮存储一次损失函数，如果损失函数的值是当前最小的值，说明当前是模型最优的时候，我们将其保存，如果稍后有更优的值，将覆盖此次值；如果损失函数的值没有增大，那我们就将Learning rate减小一半。</p>
<p>为什么要减小呢？实际上模型训练的过程和下山的过程很像，Learning Rate就是我们步子的大小。我们训练的过程实际上就是从当前位置走到最低点。在最开始的时候我们步子很大，所以下降的很快，过了一会儿，我们发现因为我们步子太长，一直在一个坑的两侧迈来迈去，进不到坑里面。那么怎么办呢？只要步子小一点就行了！这也是Scheduler的作用，在训练受到阻碍的时候帮助我们把Learning Rate减小。</p>
<p>现在训练完成，我们只需要新建一个模型，读取刚才模型最优时候的状态，再用最优模型来预测测试集数据即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">best_model = Model(config[<span class="string">"D_in"</span>],config[<span class="string">"H"</span>],config[<span class="string">"D_out"</span>])</span><br><span class="line"><span class="keyword">if</span> config[<span class="string">"USE_CUDA"</span>]:</span><br><span class="line">    best_model = best_model.cuda()</span><br><span class="line">best_model.load_state_dict(torch.load(<span class="string">"model.pth"</span>))</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_target = best_model.predict(test_tensor)</span><br><span class="line">test_target = test_target.cpu().numpy()</span><br></pre></td></tr></table></figure><br>注意，我们在使用GPU训练之后，要将Tensor从GPU上推回CPU。<br>最后我们把结果保存成csv文件即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">res = &#123;</span><br><span class="line">    <span class="string">"PassengerId"</span>:test_backup[<span class="string">"PassengerId"</span>],</span><br><span class="line">    <span class="string">"Survived"</span>:test_target</span><br><span class="line">&#125;</span><br><span class="line">res_dataframe = pd.DataFrame(res)</span><br><span class="line">res_dataframe.to_csv(<span class="string">"result.csv"</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://img-blog.csdnimg.cn/20200219123329275.png" alt=""></p>
<p>可以看到，我们的准确率为77.51%，<a href="https://blog.csdn.net/Kayaobi/article/details/104397008" target="_blank" rel="noopener">下一篇文章</a>使用的多分类器投票将进一步提升正确率。</p>
<p>源代码： <a href="https://github.com/Dai98/Kaggle-Competitions/tree/master/Titanic%20Survival" target="_blank" rel="noopener">Github</a>      <a href="https://www.kaggle.com/danielrx/using-deep-learning-to-predict-titanic-survival?scriptVersionId=28904347" target="_blank" rel="noopener">Kaggle</a></p>
<h3 id="四、参考资料"><a href="#四、参考资料" class="headerlink" title="四、参考资料"></a>四、参考资料</h3><p>[1]. <a href="https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy" target="_blank" rel="noopener">A Data Science Framework: To Achieve 99% Accuracy</a><br>[2]. <a href="https://blog.csdn.net/weixin_43637773/article/details/88246125" target="_blank" rel="noopener">Python进行泰坦尼克生存预测</a><br>[3]. <a href="https://blog.csdn.net/lizzy05/article/details/90521909?ops_request_misc=%7B%22request%5Fid%22%3A%22158208705919725211964652%22%2C%22scm%22%3A%2220140713.130056874..%22%7D&amp;request_id=158208705919725211964652&amp;biz_id=0&amp;utm_source=distribute.pc_search_result.none-task" target="_blank" rel="noopener">PyTorch实现二分类器</a></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>DanielRX
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/Kaggle%E5%AE%9E%E6%88%98/Kaggle%E5%AE%9E%E6%88%98%EF%BC%9A%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%B9%B8%E5%AD%98%E8%80%85%E9%A2%84%E6%B5%8B%20-%20%E4%B8%8A/" title="Kaggle实战：泰坦尼克幸存者预测 - 上">http://yoursite.com/Kaggle实战/Kaggle实战：泰坦尼克幸存者预测 - 上/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" rel="prev" title="交叉熵损失函数">
      <i class="fa fa-chevron-left"></i> 交叉熵损失函数
    </a></div>
      <div class="post-nav-item">
    <a href="/Kaggle%E5%AE%9E%E6%88%98/Kaggle%E5%AE%9E%E6%88%98%EF%BC%9A%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%B9%B8%E5%AD%98%E8%80%85%E9%A2%84%E6%B5%8B%20-%E4%B8%8B/" rel="next" title="Kaggle实战：泰坦尼克幸存者预测 -下">
      Kaggle实战：泰坦尼克幸存者预测 -下 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#一、数据预处理"><span class="nav-number">1.</span> <span class="nav-text">一、数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二、变量选择"><span class="nav-number">2.</span> <span class="nav-text">二、变量选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三、模型搭建"><span class="nav-number">3.</span> <span class="nav-text">三、模型搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#四、参考资料"><span class="nav-number">4.</span> <span class="nav-text">四、参考资料</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">DanielRX</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Dai98" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Dai98" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Kayaobi" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Kayaobi" rel="noopener" target="_blank"><i class="fa fa-fw fa-crosshairs"></i>CSDN</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DanielRX</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">42k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">39 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.7' zIndex='-1' count='199' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

</body>
</html>
